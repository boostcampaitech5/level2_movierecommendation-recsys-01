{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import Tuple\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    train_df = pd.read_csv(os.path.join(data_dir, 'train/train_ratings.csv')).drop('time', axis=1)\n",
    "    sub_df = pd.read_csv(os.path.join(data_dir, 'eval/sample_submission.csv'))\n",
    "    \n",
    "    return train_df, sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>4643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>2140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154466</th>\n",
       "      <td>138493</td>\n",
       "      <td>44022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154467</th>\n",
       "      <td>138493</td>\n",
       "      <td>4958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154468</th>\n",
       "      <td>138493</td>\n",
       "      <td>68319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154469</th>\n",
       "      <td>138493</td>\n",
       "      <td>40819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154470</th>\n",
       "      <td>138493</td>\n",
       "      <td>27311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5154471 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           user   item\n",
       "0            11   4643\n",
       "1            11    170\n",
       "2            11    531\n",
       "3            11    616\n",
       "4            11   2140\n",
       "...         ...    ...\n",
       "5154466  138493  44022\n",
       "5154467  138493   4958\n",
       "5154468  138493  68319\n",
       "5154469  138493  40819\n",
       "5154470  138493  27311\n",
       "\n",
       "[5154471 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, sub_df = load_data(\"../../data/\")\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>318</td>\n",
       "      <td>Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>318</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2571</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2571</td>\n",
       "      <td>Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2571</td>\n",
       "      <td>Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15928</th>\n",
       "      <td>109850</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15929</th>\n",
       "      <td>8605</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15930</th>\n",
       "      <td>8605</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15931</th>\n",
       "      <td>3689</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15932</th>\n",
       "      <td>8130</td>\n",
       "      <td>Documentary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15933 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         item        genre\n",
       "0         318        Crime\n",
       "1         318        Drama\n",
       "2        2571       Action\n",
       "3        2571       Sci-Fi\n",
       "4        2571     Thriller\n",
       "...       ...          ...\n",
       "15928  109850        Drama\n",
       "15929    8605       Action\n",
       "15930    8605       Comedy\n",
       "15931    3689       Comedy\n",
       "15932    8130  Documentary\n",
       "\n",
       "[15933 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_df = pd.read_csv(\"../../data/train/genres.tsv\", sep=\"\\t\")\n",
    "genre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item\n",
       "1         [Adventure, Animation, Children, Comedy, Fantasy]\n",
       "2                            [Adventure, Children, Fantasy]\n",
       "3                                         [Comedy, Romance]\n",
       "4                                  [Comedy, Drama, Romance]\n",
       "5                                                  [Comedy]\n",
       "                                ...                        \n",
       "118700                                              [Drama]\n",
       "118900                                              [Drama]\n",
       "118997                 [Children, Comedy, Fantasy, Musical]\n",
       "119141                                     [Action, Comedy]\n",
       "119145                   [Action, Adventure, Comedy, Crime]\n",
       "Name: genre, Length: 6807, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_df.groupby('item')['genre'].apply(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Crime': 0,\n",
       " 'Drama': 1,\n",
       " 'Action': 2,\n",
       " 'Sci-Fi': 3,\n",
       " 'Thriller': 4,\n",
       " 'Comedy': 5,\n",
       " 'Romance': 6,\n",
       " 'War': 7,\n",
       " 'Adventure': 8,\n",
       " 'Fantasy': 9,\n",
       " 'Horror': 10,\n",
       " 'Mystery': 11,\n",
       " 'Animation': 12,\n",
       " 'Children': 13,\n",
       " 'Film-Noir': 14,\n",
       " 'Musical': 15,\n",
       " 'Western': 16,\n",
       " 'Documentary': 17}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre2idx = {v:i for i, v in enumerate(genre_df['genre'].unique())}\n",
    "genre2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 sequence에서 max_len만큼 sampling\n",
    "# tail_ratio: max_len의 tail_ratio만큼은 제일 마지막에서 샘플링, 나머지는 중간에서 랜덤 샘플링\n",
    "def seq_sampling(total: pd.Series, max_len: int, tail_ratio: float) -> np.array:\n",
    "    if total.size > max_len:\n",
    "        tail_len = int(max_len * tail_ratio)\n",
    "        sample_idx = np.random.choice(np.arange(0, total.size - tail_len), max_len - tail_len, replace=False)\n",
    "        sample_idx = np.sort(sample_idx)\n",
    "        sample_seq = total[sample_idx]\n",
    "        if tail_len != 0:\n",
    "            sample_seq = np.append(sample_seq, total[-tail_len:])\n",
    "    else :\n",
    "        sample_seq = total\n",
    "        \n",
    "    return sample_seq\n",
    "\n",
    "\n",
    "# valid, test sequence에 k개 mask 섞어줌\n",
    "def mix_mask(temp_seq: np.array, k: int, mask: int) -> np.array:\n",
    "    seq = np.zeros(temp_seq.size+k, dtype=int)\n",
    "    seq[-k//2:] = mask\n",
    "    mask_idx = np.sort(np.random.choice(np.arange(0, temp_seq.size+(k//2)), k//2, replace=False))\n",
    "    seq[mask_idx] = mask\n",
    "    seq[seq == 0] = temp_seq\n",
    "    \n",
    "    return seq\n",
    "\n",
    "\n",
    "def add_padding(seq: np.array, max_len: int) -> np.array:\n",
    "    pad_len = max_len - seq.size\n",
    "    seq = np.append([0] * pad_len, seq)\n",
    "    \n",
    "    return seq\n",
    "\n",
    "\n",
    "def process_data(train_df: pd.DataFrame,\n",
    "                 genre_df: pd.DataFrame,\n",
    "                 max_len: int,\n",
    "                 k: int,\n",
    "                 n_samples: int,\n",
    "                 tail_ratio: float) -> Tuple[dict, int, int, dict]:\n",
    "    item_idx = train_df['item'].unique()\n",
    "    user_idx = train_df['user'].unique()\n",
    "    \n",
    "    user2idx = {user:idx for idx,user in enumerate(user_idx)}\n",
    "    item2idx = {item:idx+1 for idx,item in enumerate(item_idx)}\n",
    "    idx2item = {idx+1:item for idx,item in enumerate(item_idx)}\n",
    "    genre2idx = {v:i for i, v in enumerate(genre_df['genre'].unique())}\n",
    "    n_items = len(item2idx)\n",
    "    n_users = len(user2idx)\n",
    "    n_genres = len(genre2idx)\n",
    "    \n",
    "    train_df['user'] = train_df['user'].map(user2idx)\n",
    "    train_df['item'] = train_df['item'].map(item2idx)\n",
    "    genre_df['item'] = genre_df['item'].map(item2idx)\n",
    "    genre_df['genre'] = genre_df['genre'].map(genre2idx)\n",
    "    genre_data = genre_df.groupby('item')['genre'].apply(np.array)\n",
    "    \n",
    "    total = train_df.groupby('user')['item'].apply(np.array)\n",
    "    train_seq = list()\n",
    "    valid_seq = list()\n",
    "    valid_target = list()\n",
    "    infer_seq = list()\n",
    "    valid_cand = list()\n",
    "    infer_cand = list()\n",
    "    for user_idx, user_total in enumerate(tqdm(total)):\n",
    "        # user_valid_target: 맨 뒤에서 절반, 중간에서 절반 추출\n",
    "        user_valid_target = np.random.choice(user_total[:-(k//2)], (k//2), replace=False)\n",
    "        user_valid_target = np.append(user_valid_target, user_total[-(k-k//2):])\n",
    "        valid_target.append(user_valid_target)\n",
    "        \n",
    "        # user_total_train: user_valid_target 제외\n",
    "        user_total_train = user_total[~np.isin(user_total, user_valid_target)]\n",
    "        \n",
    "        # user_train_seq: user_total_train에서 max_len만큼 샘플링(n_samples 횟수 만큼)\n",
    "        for _ in range(n_samples):\n",
    "            user_train_seq = seq_sampling(user_total_train, max_len, tail_ratio)\n",
    "            train_seq.append(user_train_seq)\n",
    "\n",
    "        # user_valid_seq: user_total_train에서 max_len-k만큼 샘플링. 이후 k개의 masking 섞어줌 (절반은 맨 뒤에, 나머지는 중간에 랜덤)\n",
    "        temp_valid_seq = seq_sampling(user_total_train, max_len-k, tail_ratio)\n",
    "        user_valid_seq = mix_mask(temp_valid_seq, k, n_items+1)\n",
    "        # add padding\n",
    "        if user_valid_seq.size < max_len :\n",
    "            user_valid_seq = add_padding(user_valid_seq, max_len)\n",
    "        valid_seq.append(torch.tensor(user_valid_seq).unsqueeze(0))\n",
    "        \n",
    "        temp_infer_seq = seq_sampling(user_total, max_len-k, 0.25)\n",
    "        user_infer_seq = mix_mask(temp_infer_seq, k, n_items+1)\n",
    "        if user_infer_seq.size < max_len :\n",
    "            user_infer_seq = add_padding(user_infer_seq, max_len)\n",
    "        infer_seq.append(torch.tensor(user_infer_seq).unsqueeze(0))\n",
    "        \n",
    "        # user_valid_cand: 전체 negative + user_valid_target\n",
    "        user_infer_cand = np.setdiff1d(np.arange(1, n_items+1), user_total)\n",
    "        # user_infer_candL 전체 negative\n",
    "        user_valid_cand = np.append(user_valid_target, user_infer_cand)\n",
    "        valid_cand.append(user_valid_cand)\n",
    "        infer_cand.append(user_infer_cand)\n",
    "        \n",
    "    data = {'train': train_seq,\n",
    "            'valid': valid_seq,\n",
    "            'valid_target': valid_target,\n",
    "            'infer': infer_seq,\n",
    "            'valid_cand': valid_cand,\n",
    "            'infer_cand': infer_cand,\n",
    "            'genre': genre_data}\n",
    "    \n",
    "    return data, n_items, n_users, n_genres, idx2item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31360/31360 [00:27<00:00, 1155.78it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data, n_items, n_users, n_genres, idx2item = process_data(train_df, genre_df, 50, 10, 1, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: genre, dtype: int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT4RecDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 train_data: list,\n",
    "                 n_users: int,\n",
    "                 n_items: int,\n",
    "                 max_len: int,\n",
    "                 k: int,\n",
    "                 mask_prob: float):\n",
    "        self.train_data = train_data\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.max_len = max_len\n",
    "        self.k = k\n",
    "        self.mask_prob = mask_prob\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_data)\n",
    "\n",
    "    def __getitem__(self, user_idx: int) -> Tuple[torch.tensor, torch.tensor]: \n",
    "        seq = self.train_data[user_idx]\n",
    "        masked_seq = seq.copy()\n",
    "        labels = np.zeros_like(seq)\n",
    "        \n",
    "        # 중간 랜덤 5개 masking\n",
    "        mask_idx = np.random.choice(np.arange(0, seq.size-(self.k//2)), int(seq.size*self.mask_prob))\n",
    "        masked_seq[mask_idx] = self.n_items+1\n",
    "        # 마지막 5개 masking\n",
    "        masked_seq[-(self.k//2):] = self.n_items+1\n",
    "        labels[mask_idx] = seq[mask_idx]\n",
    "        labels[-(self.k//2):] = seq[-(self.k//2):]\n",
    "                \n",
    "        # zero padding\n",
    "        if seq.size < self.max_len:\n",
    "            pad_len = self.max_len - seq.size\n",
    "            masked_seq = np.append([0] * pad_len, masked_seq)\n",
    "            labels = np.append([0] * pad_len, labels)\n",
    "        \n",
    "        masked_seq = torch.LongTensor(masked_seq)\n",
    "        labels = torch.LongTensor(labels)\n",
    "        \n",
    "        return masked_seq, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user\n",
       "1916     2912\n",
       "12416    1980\n",
       "5563     1842\n",
       "7417     1830\n",
       "20832    1795\n",
       "         ... \n",
       "2528       32\n",
       "29208      28\n",
       "24060      22\n",
       "15643      19\n",
       "12135      16\n",
       "Name: count, Length: 31360, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['user'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31360/31360 [00:04<00:00, 6408.46it/s]\n"
     ]
    }
   ],
   "source": [
    "data, n_users, n_items, idx2item = process_data(train_df, 50, 10, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31360"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12135\n",
      "[ 83 375 206 160 314 293]\n",
      "15643\n",
      "[ 286  272   73 1908 6408   74  771  765 6440]\n",
      "24060\n",
      "[1629  629 5073 5103 3246 3456 5092 2687 5072 6685 4178 4311]\n",
      "29208\n",
      "[6007 3557 1793 1187 4264 5407 5211 2713 1765 3239 1646   47 4175 5014\n",
      " 5715 3982 5444 4160]\n"
     ]
    }
   ],
   "source": [
    "for idx, seq in enumerate(data['train']):\n",
    "    if seq.size < 20:\n",
    "        print(idx)\n",
    "        print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "[ 83 375 206 160 314 293]\n"
     ]
    }
   ],
   "source": [
    "print(data['train'][12135].size)\n",
    "print(data['train'][12135])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0   83 6808  375  206 6808  160 6808 6808\n",
      "  314 6808  293 6808 6808 6808 6808 6808]\n"
     ]
    }
   ],
   "source": [
    "print(data['valid'][12135].size)\n",
    "print(data['valid'][12135])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 310  201 1203  199  264  266  631 1420  601  444]\n"
     ]
    }
   ],
   "source": [
    "print(data['valid_target'][12135])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0 6808  199 6808   83\n",
      "  375 1203  206 6808  264  160  310  314  293  201  266  631 1420 6808\n",
      " 6808  601  444 6808 6808 6808 6808 6808]\n"
     ]
    }
   ],
   "source": [
    "print(data['infer'][12135].size)\n",
    "print(data['infer'][12135])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT4RecDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 train_data: pd.Series,\n",
    "                 n_users: int,\n",
    "                 n_items: int,\n",
    "                 max_len: int,\n",
    "                 k:int,\n",
    "                 mask_prob: float):\n",
    "        self.train_data = train_data\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.max_len = max_len\n",
    "        self.k = k\n",
    "        self.mask_prob = mask_prob\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_data)\n",
    "\n",
    "    def __getitem__(self, user_idx: int) -> Tuple[torch.tensor, torch.tensor]: \n",
    "        seq = self.train_data[user_idx]\n",
    "        masked_seq = seq.copy()\n",
    "        labels = np.zeros_like(seq)\n",
    "        # for item_idx in seq[:-(self.k//2)]:\n",
    "        #     prob = np.random.random()\n",
    "        #     if prob < self.mask_prob:\n",
    "        #         labels.append(item_idx)  # 학습에 사용\n",
    "        #         masked_seq.append(self.n_items+1)\n",
    "        #     else:\n",
    "        #         labels.append(0)  # 학습에 사용 X\n",
    "        #         masked_seq.append(item_idx)\n",
    "        # labels.extend(seq[-(self.k//2):])\n",
    "        # masked_seq.extend([self.n_items+1]*(self.k//2))\n",
    "        \n",
    "        mask_idx = np.random.choice(np.arange(0, seq.size-(self.k//2)), int(seq.size*self.mask_prob))\n",
    "        # 중간 랜덤 5개\n",
    "        masked_seq[mask_idx] = self.n_items+1\n",
    "        # 마지막 5개\n",
    "        masked_seq[-(self.k//2):] = self.n_items+1\n",
    "        labels[mask_idx] = seq[mask_idx]\n",
    "        labels[-(self.k//2):] = seq[-(self.k//2):]\n",
    "                \n",
    "        # zero padding\n",
    "        if seq.size < self.max_len:\n",
    "            pad_len = self.max_len - seq.size\n",
    "            masked_seq = np.append([0] * pad_len, masked_seq)\n",
    "            labels = np.append([0] * pad_len, labels)\n",
    "        \n",
    "        masked_seq = torch.LongTensor(masked_seq)\n",
    "        labels = torch.LongTensor(labels)\n",
    "        \n",
    "        return masked_seq, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BERT4RecDataset(data['train'], n_users, n_items, 50, 10, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31360"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,   83, 6808, 6808, 6808,\n",
       "         6808, 6808]),\n",
       " tensor([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0, 375, 206, 160, 314, 293]))"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[12135]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0, 375, 206, 160, 314, 293])"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = dataset[12135][1]\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 14,  92, 158, 270, 284, 344, 351, 357, 364, 371])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[label != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          356, 1421, 1423, 1415,  666,  255, 1404, 1400,  743, 1424,  261,   81,\n",
       "          859,  266,  267,  199,   85,  268, 1420,  741,  735,  314,  667,   80,\n",
       "         1143,  732,  600, 1087,  602,   47,  554,  265,  203,  625,  739, 1427,\n",
       "         1069, 6808]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['valid'][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([6, 5, 4]),\n",
       "indices=tensor([4, 0, 1]))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([5, 4, 2, 3, 6, 1])\n",
    "x.topk(3, largest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 embed_dim: int,\n",
    "                 n_heads: int,\n",
    "                 pffn_hidden_dim: int,\n",
    "                 dropout_rate: float):\n",
    "        super(EncoderLayer, self).__init__()        \n",
    "        self.mha = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=n_heads, dropout=dropout_rate)\n",
    "        self.pffn = nn.Sequential(\n",
    "                    nn.Linear(embed_dim, pffn_hidden_dim),\n",
    "                    nn.GELU(),\n",
    "                    nn.Linear(pffn_hidden_dim, embed_dim)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.layer_norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.layer_norm2 = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "    def forward(self, embed_seq, padding_mask):\n",
    "        \"\"\"\n",
    "        attention -> residual connection -> pointwise feed forward network -> residual connection\n",
    "        input: size(batch_size, max_len, embed_dim)\n",
    "        output: size(batch_size, max_len, embed_dim)\n",
    "        \"\"\"\n",
    "        embed_seq = embed_seq.transpose(0, 1)\n",
    "        mha_out, _ = self.mha(embed_seq, embed_seq, embed_seq, key_padding_mask=padding_mask)\n",
    "        mha_out = mha_out.transpose(0, 1)\n",
    "        mha_out = self.layer_norm1(self.dropout(mha_out) + embed_seq.transpose(0, 1))\n",
    "        \n",
    "        pffn_out = self.pffn(mha_out)\n",
    "        out = self.layer_norm2(self.dropout(pffn_out) + mha_out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    \n",
    "class BERT4Rec(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_items: int,\n",
    "                 embed_dim: int,\n",
    "                 max_len: int,\n",
    "                 n_layers: int,\n",
    "                 n_heads: int,\n",
    "                 pffn_hidden_dim: int,\n",
    "                 dropout_rate: float,\n",
    "                 device: torch.device):\n",
    "        super(BERT4Rec, self).__init__()\n",
    "        self.max_len = max_len\n",
    "        self.n_layers = n_layers\n",
    "        self.device = device\n",
    "        \n",
    "        self.item_embed = nn.Embedding(n_items+2, embed_dim, padding_idx=0)\n",
    "        self.pos_embed = nn.Embedding(max_len, embed_dim)\n",
    "        \n",
    "        self.encoder_layer = nn.ModuleList(\n",
    "            [EncoderLayer(embed_dim, n_heads, pffn_hidden_dim, dropout_rate)\n",
    "             for _ in range(self.n_layers)]\n",
    "            )\n",
    "        \n",
    "        self.out_layer = nn.Linear(embed_dim, n_items+1)\n",
    "        \n",
    "        \n",
    "    def embedding_layer(self, seq: torch.tensor) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        input: shape(batch_size, max_len)\n",
    "        output: shape(batch_size, max_len, embed_dim)\n",
    "        \"\"\"\n",
    "        item_embed = self.item_embed(seq)\n",
    "        pos = torch.arange(self.max_len, device=self.device).unsqueeze(0)\n",
    "        pos_embed = self.pos_embed(pos).repeat(item_embed.size(0), 1, 1)\n",
    "        embed_seq = item_embed + pos_embed\n",
    "        \n",
    "        return embed_seq\n",
    "    \n",
    "    def forward(self, seq: torch.tensor) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        embedding -> encoder -> output\n",
    "        input: shape(batch_size, max_len)\n",
    "        output: shape(batch_size, max_len, n_items+1)\n",
    "        \"\"\"\n",
    "        embed_seq = self.embedding_layer(seq)\n",
    "        \n",
    "        padding_mask = (seq==0).bool().to(self.device)\n",
    "        out = embed_seq\n",
    "        for block in self.encoder_layer:\n",
    "            out = block(out, padding_mask)\n",
    "            \n",
    "        out = self.out_layer(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(output, target):\n",
    "    \"\"\"\n",
    "    Computes Recall@k for the specified values of k\n",
    "\n",
    "    Args:\n",
    "    output (torch.Tensor): model's output probabilities, size (batch_size, max_len, num_classes)\n",
    "    target (torch.Tensor): ground truth, size (batch_size, max_len)\n",
    "\n",
    "    Returns:\n",
    "    float, recall value\n",
    "    \"\"\"\n",
    "    output_reshaped = output.view(-1, output.size(-1))  # Reshape output to (batch_size * max_len, num_classes)\n",
    "    target_reshaped = (target - 1).view(-1)  # Reshape target to (batch_size * max_len,)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=-1)  # ignore padding index\n",
    "    loss = criterion(output_reshaped, target_reshaped)\n",
    "\n",
    "    mask_idx = (target != 0)  # get indices of non-zero target elements\n",
    "    print(mask_idx)\n",
    "\n",
    "    output = output[mask_idx]  # filter output by these indices\n",
    "    target = target[mask_idx] - 1  # filter target by these indices\n",
    "    print(output)\n",
    "    print(f\"target: {target}\")\n",
    "    _, pred = output.topk(1, dim=-1)  # get top k predictions\n",
    "    pred = pred.squeeze(-1)\n",
    "    print(f\"pred: {pred}\")\n",
    "    correct = pred.eq(target)  # compare predictions to target\n",
    "\n",
    "    recall = correct.sum().item() / correct.size(0)  # calculate recall\n",
    "\n",
    "    return recall, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1000, 0.2000, 0.7000],\n",
      "        [0.3000, 0.2000, 0.5000],\n",
      "        [0.1000, 0.3000, 0.6000],\n",
      "        [0.2000, 0.1000, 0.7000],\n",
      "        [0.5000, 0.3000, 0.2000],\n",
      "        [0.2000, 0.1000, 0.7000],\n",
      "        [0.4000, 0.3000, 0.3000],\n",
      "        [0.6000, 0.4000, 0.0000],\n",
      "        [0.1000, 0.2000, 0.7000],\n",
      "        [0.2000, 0.3000, 0.5000],\n",
      "        [0.3000, 0.1000, 0.6000],\n",
      "        [0.4000, 0.7000, 0.1000],\n",
      "        [0.6000, 0.3000, 0.1000],\n",
      "        [0.2000, 0.1000, 0.7000],\n",
      "        [0.1000, 0.6000, 0.3000],\n",
      "        [0.7000, 0.3000, 0.0000],\n",
      "        [0.3000, 0.3000, 0.4000],\n",
      "        [0.2000, 0.2000, 0.6000],\n",
      "        [0.5000, 0.2000, 0.3000],\n",
      "        [0.4000, 0.6000, 0.0000]])\n",
      "tensor([ 0, -1,  2, -1,  1,  2, -1, -1, -1,  0, -1,  2,  0, -1,  2, -1, -1,  2,\n",
      "        -1,  1])\n",
      "tensor([[ True, False,  True, False],\n",
      "        [ True,  True, False, False],\n",
      "        [False,  True, False,  True],\n",
      "        [ True, False,  True, False],\n",
      "        [False,  True, False,  True]])\n",
      "tensor([[0.1000, 0.2000, 0.7000],\n",
      "        [0.1000, 0.3000, 0.6000],\n",
      "        [0.5000, 0.3000, 0.2000],\n",
      "        [0.2000, 0.1000, 0.7000],\n",
      "        [0.2000, 0.3000, 0.5000],\n",
      "        [0.4000, 0.7000, 0.1000],\n",
      "        [0.6000, 0.3000, 0.1000],\n",
      "        [0.1000, 0.6000, 0.3000],\n",
      "        [0.2000, 0.2000, 0.6000],\n",
      "        [0.4000, 0.6000, 0.0000]])\n",
      "target: tensor([0, 2, 1, 2, 0, 2, 0, 2, 2, 1])\n",
      "pred: tensor([2, 2, 0, 2, 2, 1, 0, 1, 2, 1])\n",
      "Loss tensor(1.0516)\n",
      "Recall: 0.5\n"
     ]
    }
   ],
   "source": [
    "# logits for each item\n",
    "output = torch.tensor([\n",
    "    [[0.1, 0.2, 0.7], [0.3, 0.2, 0.5], [0.1, 0.3, 0.6], [0.2, 0.1, 0.7]],  # batch 1\n",
    "    [[0.5, 0.3, 0.2], [0.2, 0.1, 0.7], [0.4, 0.3, 0.3], [0.6, 0.4, 0.0]],  # batch 2\n",
    "    [[0.1, 0.2, 0.7], [0.2, 0.3, 0.5], [0.3, 0.1, 0.6], [0.4, 0.7, 0.1]],  # batch 3\n",
    "    [[0.6, 0.3, 0.1], [0.2, 0.1, 0.7], [0.1, 0.6, 0.3], [0.7, 0.3, 0.0]],  # batch 4\n",
    "    [[0.3, 0.3, 0.4], [0.2, 0.2, 0.6], [0.5, 0.2, 0.3], [0.4, 0.6, 0.0]]   # batch 5\n",
    "])\n",
    "\n",
    "# true classes for each item, with some items unmasked (represented by 0)\n",
    "target = torch.tensor([\n",
    "    [1, 0, 3, 0],  # batch 1\n",
    "    [2, 3, 0, 0],  # batch 2\n",
    "    [0, 1, 0, 3],  # batch 3\n",
    "    [1, 0, 3, 0],  # batch 4\n",
    "    [0, 3, 0, 2]   # batch 5\n",
    "])\n",
    "\n",
    "recall, loss = metric(output, target)\n",
    "print(\"Loss\", loss)\n",
    "print(\"Recall:\", recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
